#!/bin/bash
#SBATCH --partition=defq       # the requested queue
#SBATCH --nodes=1              # number of nodes to use
#SBATCH --tasks-per-node=1     # for parallel distributed jobs
#SBATCH --cpus-per-task=4      # for multi-threaded jobs
#SBATCH --mem-per-cpu=4G      # in megabytes, unless unit explicitly stated
#SBATCH --error=logs/%J.err         # redirect stderr to this file
#SBATCH --output=logs/%J.out        # redirect stdout to this file
#SBATCH --mail-user=wilsoncl6@cardiff.ac.uk     # email
#SBATCH --mail-type=BEGIN,END,FAIL      # email on job start, end, and/or failure


#QC 4 loop script
#Heritage and wakefield 59-64 samples

echo "Usable Environment Variables:"
echo "============================="
echo "hostname=$(hostname)"
echo \$SLURM_JOB_ID=${SLURM_JOB_ID}
echo \$SLURM_NTASKS=${SLURM_NTASKS}
echo \$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}
echo \$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}
echo \$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}
echo \$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}

## Load some Modules
module load fastp/v0.20

## Set up working directory
export workingdir=/mnt/scratch/charlotte

## The commands you want to run

# List of sequences
list=("HT-64" "HT-63" "HT-62" "WA-61" "WA-60" "WA-59")

# fastqc the raw data (assuming PE data)
for i in ${list[@]}
do
        echo ${i}
        
        fastp -i $workingdir/raw/${i}_1.fastq.gz -I $workingdir/raw/${i}_2.fastq.gz -o $workingdir/trimmed/${i}_fp1.fastq.gz -O $workingdir/raw/${i}_fp2.fastq.gz --detect_adapter_for_pe --trim_poly_g --correction


done

